{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Importing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T13:19:27.884240Z",
     "start_time": "2025-01-15T13:19:26.365995Z"
    }
   },
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchmetrics\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.loggers import CSVLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", font_scale=1.5, rc={\"axes.unicode_minus\": False})\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "pl.seed_everything(seed)\n"
   ],
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorchmetrics\u001B[39;00m\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\__init__.py:2475\u001B[0m\n\u001B[0;32m   2471\u001B[0m     torch_module_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin([\u001B[38;5;18m__name__\u001B[39m, device_type])\n\u001B[0;32m   2472\u001B[0m     sys\u001B[38;5;241m.\u001B[39mmodules[torch_module_name] \u001B[38;5;241m=\u001B[39m module\n\u001B[1;32m-> 2475\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m   2476\u001B[0m     export \u001B[38;5;28;01mas\u001B[39;00m export,\n\u001B[0;32m   2477\u001B[0m     func \u001B[38;5;28;01mas\u001B[39;00m func,\n\u001B[0;32m   2478\u001B[0m     library \u001B[38;5;28;01mas\u001B[39;00m library,\n\u001B[0;32m   2479\u001B[0m     return_types \u001B[38;5;28;01mas\u001B[39;00m return_types,\n\u001B[0;32m   2480\u001B[0m )\n\u001B[0;32m   2481\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cond \u001B[38;5;28;01mas\u001B[39;00m cond, while_loop \u001B[38;5;28;01mas\u001B[39;00m while_loop\n\u001B[0;32m   2482\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m vmap \u001B[38;5;28;01mas\u001B[39;00m vmap\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\export\\__init__.py:64\u001B[0m\n\u001B[0;32m     41\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msymbolic_shapes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m StrictMinMaxConstraint\n\u001B[0;32m     44\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     45\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConstraint\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     46\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDim\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     60\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnflattenedModule\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     61\u001B[0m ]\n\u001B[1;32m---> 64\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdynamic_shapes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Constraint, Dim, dims, ShapesCollection\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram, ModuleCallEntry, ModuleCallSignature\n\u001B[0;32m     66\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mgraph_signature\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExportBackwardSignature, ExportGraphSignature\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\export\\dynamic_shapes.py:23\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     12\u001B[0m     _get_node_type,\n\u001B[0;32m     13\u001B[0m     BUILTIN_TYPES,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     20\u001B[0m     tree_map_with_path,\n\u001B[0;32m     21\u001B[0m )\n\u001B[1;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexported_program\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ExportedProgram\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m TYPE_CHECKING:\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msympy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Symbol\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\export\\exported_program.py:26\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcontextlib\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m contextmanager\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     13\u001B[0m     Any,\n\u001B[0;32m     14\u001B[0m     Callable,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m     Union,\n\u001B[0;32m     24\u001B[0m )\n\u001B[1;32m---> 26\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m autograd_not_implemented\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_library\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfake_class_registry\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FakeScriptObject\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfx\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m first_call_function_nn_module_stack\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\_higher_order_ops\\__init__.py:1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcond\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m cond\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mflex_attention\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m      3\u001B[0m     flex_attention,\n\u001B[0;32m      4\u001B[0m     flex_attention_backward,\n\u001B[0;32m      5\u001B[0m )\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_higher_order_ops\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mhints_wrap\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m hints_wrapper\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\_higher_order_ops\\cond.py:6\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mlogging\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_subclasses\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional_tensor\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DispatchKey\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:9\u001B[0m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Any, Callable, ContextManager, Dict, List, Optional, Tuple, Union\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_inductor\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconfig\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01minductor_config\u001B[39;00m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_pytree\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpytree\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_C\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m _functionalization_reapply_views_tls \u001B[38;5;28;01mas\u001B[39;00m _reapply_views\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\_inductor\\config.py:44\u001B[0m\n\u001B[0;32m     40\u001B[0m verbose_progress \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m     42\u001B[0m \u001B[38;5;66;03m# use fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     43\u001B[0m fx_graph_cache \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m---> 44\u001B[0m     os\u001B[38;5;241m.\u001B[39menviron\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTORCHINDUCTOR_FX_GRAPH_CACHE\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m0\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mis_fbcode\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     45\u001B[0m )\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# use remote fx aot graph codegen cache\u001B[39;00m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;66;03m# False: Disables the cache\u001B[39;00m\n\u001B[0;32m     49\u001B[0m \u001B[38;5;66;03m# True: Enables the cache\u001B[39;00m\n\u001B[0;32m     50\u001B[0m \u001B[38;5;66;03m# None: Not set -- Off for OSS, JustKnobs based for internal\u001B[39;00m\n\u001B[0;32m     51\u001B[0m fx_graph_remote_cache: Optional[\u001B[38;5;28mbool\u001B[39m] \u001B[38;5;241m=\u001B[39m fx_graph_remote_cache_default()\n",
      "File \u001B[1;32mC:\\ProgramData\\anaconda3\\envs\\cnn\\lib\\site-packages\\torch\\_inductor\\config.py:9\u001B[0m, in \u001B[0;36mis_fbcode\u001B[1;34m()\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_fbcode\u001B[39m() \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[1;32m----> 9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mversion\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgit_version\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: partially initialized module 'torch' has no attribute 'version' (most likely due to a circular import)"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "<h1>Data Preparation</h1>"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"train_data_path\": \"../datasets/train\",\n",
    "    \"val_data_path\": \"../datasets/val\",\n",
    "    \"batch_size\": 32,\n",
    "    \"image_size\": (224, 224),\n",
    "}\n",
    "\n",
    "for path in [config[\"train_data_path\"], config[\"val_data_path\"]]:\n",
    "    if not Path(path).exists():\n",
    "        raise FileNotFoundError(f\"Path not found: {path}\")\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(config[\"image_size\"]),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(degrees=10, translate=(0.1, 0.1)),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
    "    transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(config[\"image_size\"]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=config[\"train_data_path\"], transform=train_transform)\n",
    "val_dataset = datasets.ImageFolder(root=config[\"val_data_path\"], transform=val_transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False, num_workers=4)\n",
    "\n",
    "# Temporary for visualization\n",
    "temp_transform = transforms.Compose([\n",
    "    transforms.Resize(config[\"image_size\"]),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "temp_val_dataset = datasets.ImageFolder(root=config[\"val_data_path\"], transform=temp_transform)\n",
    "temp_val_loader = DataLoader(temp_val_dataset, batch_size=config[\"batch_size\"], shuffle=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Visualization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class_names = train_dataset.classes\n",
    "class_count = [train_dataset.targets.count(i) for i in range(len(class_names))]\n",
    "df = pd.DataFrame({\"Class\": class_names, \"Count\": class_count})\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "sns.barplot(x=\"Count\", y=\"Class\", data=df)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "plt.figure(figsize=(12, 20), dpi=100)\n",
    "images, labels = next(iter(temp_val_loader))\n",
    "for i in range(8):\n",
    "    ax = plt.subplot(8, 4, i + 1)\n",
    "    plt.imshow(images[i].permute(1, 2, 0).numpy())\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modeling</h1>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(256, 512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(512 * 3 * 3, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        self.accuracy = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.fc(x)\n",
    "            return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch \n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('train_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=0.0005, betas=(0.9, 0.999), eps=1e-08, weight_decay=1e-5)\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.3)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log('val_acc', acc, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        acc = self.accuracy(torch.argmax(y_hat, dim=1), y)\n",
    "        self.log('test_acc', acc)\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch\n",
    "        y_hat = self(x)\n",
    "        preds = torch.argmax(y_hat, dim=1)\n",
    "        return preds"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Train the model or ...</h5>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "num_classes = len(class_names)\n",
    "model = LitModel(num_classes=num_classes)\n",
    "logger = CSVLogger(\"../\")\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=5, mode=\"min\")\n",
    "checkpoint_callback = ModelCheckpoint(monitor='val_acc', save_top_k=1, mode='max')\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    enable_progress_bar=True,\n",
    "    log_every_n_steps=10,\n",
    "    logger=logger,\n",
    "    callbacks=[early_stop_callback, checkpoint_callback], \n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "\n",
    "trainer.fit(model, train_loader, val_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Load The Trained Model</h5>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "checkpoint_path = checkpoint_callback.best_model_path\n",
    "\n",
    "model = LitModel.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "torch.save(model, \"vehicle_classifier_customcnn.pt\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "    devices=1 if torch.cuda.is_available() else None\n",
    ")\n",
    "\n",
    "trainer.test(model, val_loader)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Predict Test Data<h1>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "pred = trainer.predict(model, val_loader)\n",
    "pred = torch.cat(pred, dim=0)\n",
    "pred = pd.DataFrame(pred.numpy(), columns=[\"Class\"])\n",
    "pred[\"Class\"] = pred[\"Class\"].apply(lambda x: class_names[x])\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "sns.countplot(y=\"Class\", data=pred)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Loss & Accuracy</h1>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "metrics_path = Path(logger.log_dir) / \"metrics.csv\"\n",
    "metrics = pd.read_csv(\"../lightning_logs/version_12/metrics.csv\")\n",
    "\n",
    "plt.figure(figsize=(12, 8), dpi=100)\n",
    "sns.lineplot(x=\"epoch\", y=\"train_loss\", data=metrics, label=\"Train Loss\", linewidth=2)\n",
    "sns.lineplot(x=\"epoch\", y=\"train_acc\", data=metrics, label=\"Train Accuracy\", linewidth=2)\n",
    "sns.lineplot(x=\"epoch\", y=\"val_loss\", data=metrics, label=\"Valid Loss\", linewidth=2)\n",
    "sns.lineplot(x=\"epoch\", y=\"val_acc\", data=metrics, label=\"Valid Accuracy\", linewidth=2)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
